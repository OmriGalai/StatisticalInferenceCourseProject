---
title: "Statistical Inference Course Project"
author: "Omri Galai"
date: "12/18/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
First let's simulate 1000 draws of 40 exponential random variables and store them in a data frame.
```{r}
set.seed(171742)
n <- 40
lambda <- 0.2
nosim <- 1000
sim <- NULL
sim <- sapply(1:nosim, function(i) sim = c(sim, rexp(n, lambda)))
sim <- as.matrix(sim)
```
Now let's take a look at the dimensions of the data frame:
```{r}
dim(sim)
```
Central limit theorem posits that the mean of sample averages approximates the population mean (1/lambda = 5, same as population sd) and its standard error should be sigma/sqrt(n):
```{r}
mean(apply(sim, 1, mean))
1/lambda
sd(apply(as.matrix(sim), 2, mean))
print((1/lambda)/sqrt(n))
```
As expected the simulation statistics are very close to computed values.