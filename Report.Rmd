---
title: "Statistical Inference Course Project"
author: "Omri Galai"
date: "12/18/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
First let's simulate 1000 draws of 40 exponential random variables and store them in a data frame.
```{r}
set.seed(5000000)
n <- 40
lambda <- 0.2
nosim <- 1000
sim <- NULL
for(i in 1:nosim) sim = rbind(sim, rexp(n, lambda))
sim <- as.matrix(sim)
```
Now let's take a look at the dimensions of the data frame:
```{r}
dim(sim)
```
Central limit theorem posits that the mean of sample averages approximates the population mean (1/lambda = 5, same as population sd) and its standard error should be sigma/sqrt(n):
```{r}
means <- apply(sim, 1, mean)
mean(means)
1/lambda
sd(means)
print((1/lambda)/sqrt(n))
```
As expected the simulation statistics are very close to computed values.
Now we shall see whether the distribution of means approximates a normal one:
```{r}
library(ggplot2)
g <- ggplot(as.data.frame(means), aes(means))
g <- g + geom_histogram(aes(y = ..density..), binwidth = 0.1, colour = "black")
g + stat_function(fun = dnorm, args = list(mean = mean(means), sd = sd(means)))
```
The histogram is centered at the mean, is mound shaped and is visibly similar to the normal density we have overlaid. We can also draw a Q-Q plot to get another visual measure of how the data conforms to the normal distribution: 
```{r}
par(mfrow = c(1,1))
qqnorm(means)
qqline(means)
```
A perfect fit would be a linear relationship between the normal quantiles (on the x axis) and the observed quantiles of the sample means (on the y axis). Based on [this blog post](https://towardsdatascience.com/q-q-plots-explained-5aa8495426c0), we see a quite small skew to the right.
We can evaluate the same using skewness as well as kurtosis, which Wikipedia define as a "measure of the "tailedness" of the probability distribution". The values for a normal distribution should be 0 and 3, respectively.
```{r}
library(moments)
skewness(means)
kurtosis(means)
```