---
title: "Statistical Inference Course Project"
author: "Omri Galai"
date: "12/18/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Simulation
First let's simulate 1000 draws of 40 exponential random variables and store them in a data frame.
```{r}
set.seed(5000000)
n <- 40
lambda <- 0.2
nosim <- 1000
sim <- NULL
for(i in 1:nosim) sim = rbind(sim, rexp(n, lambda))
sim <- as.matrix(sim)
```
Now let's take a look at the dimensions of the data frame:
```{r}
dim(sim)
```
## Mean and variance
Central limit theorem posits that the mean of sample averages approximates the population mean (1/lambda = 5, same as population sd) and its standard error should be sigma/sqrt(n):
```{r}
means <- apply(sim, 1, mean)
mean(means)
1/lambda
sd(means)
print((1/lambda)/sqrt(n))
```
As expected the simulation statistics are very close to computed values.
## Normality
Now we shall see whether the distribution of means approximates a normal one:
```{r}
library(ggplot2)
library(gridExtra)
g <- ggplot(as.data.frame(means), aes(x = means))
g <- g + geom_histogram(aes(y = ..density..), binwidth = 0.1, colour = "black")
g <- g + stat_function(fun = dnorm, args = list(mean = mean(means), sd = sd(means)), colour = "red") + labs(title = "Histogram of sample means and normal density") + theme(title = element_text(size = 8))
p <- ggplot(as.data.frame(means), aes(sample = means), xlab = "Sample means", ylab = "Density") + theme(plot.title = element_text(size = 10.5))
p <- p + stat_qq(distribution = qnorm, colour = "black") + stat_qq_line(colour = "blue")
p <- p + labs(title = "Q-Q Plot", xlab = "Normal quantiles", ylab = "Sample quantiles") + theme(plot.title = element_text(size = 10.5))
gridExtra::grid.arrange(g, p, nrow = 1)

```
The histogram is centered at the mean, is mound shaped and is visibly similar to the normal density we have overlaid.
On the Q-Q plot,  perfect normality would be a linear relationship between the normal quantiles (on the x axis) and the observed quantiles of the sample means (on the y axis). Based on [this blog post](https://towardsdatascience.com/q-q-plots-explained-5aa8495426c0), we see a minimal skew to the right.
We can evaluate the same using skewness as well as kurtosis, which Wikipedia define as a "measure of the "tailedness" of the probability distribution". The values for a normal distribution should be 0 and 3, respectively.
```{r}
library(moments)
skewness(means)
kurtosis(means)
```
Again, the data is mildly skewed to the right (skewness > 0) and has somewhat lighter tails than expected (kurtosis > 3). However, [rules](https://variation.com/wp-content/distribution_analyzer_help/hs139.htm) of [thumb](https://variation.com/wp-content/distribution_analyzer_help/hs113.htm) imply these are not sizable departure from normality. 
```